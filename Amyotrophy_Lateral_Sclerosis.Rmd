---
title: "Amyotrophic lateral sclerosi"
author: "Filippo Alberto Mirolo, 239906"
date: "26/05/2023"
output:
  pdf_document:
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

# Setting data up

```{r setup}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      tidy = TRUE, tidy.opts = list(width.cutoff = 80))
my_dir <- "C:\\Users\\filoa\\Desktop\\Network model\\ASL"
setwd(my_dir)
```

```{r, include=FALSE}
library(dplyr)
library(pathview)
library(hgu133a.db)
library(GEOquery)
library(genefilter)
library(randomForest)
library(e1071) 
library(limma)
library(R.utils)
library(umap)
library(maptools)
library(MASS)
library(pROC)
library(rlang)
library(useful)
library(plotly)
library(caret)
library(RColorBrewer)
library(glmnet)
library(ROCR)
library(igraph) 
library(rScudo)
library(gprofiler2) 
library(biomaRt)
library(stringr)
```

# Loading data and first look

```{r echo = FALSE, include=FALSE}
als <- getGEO(filename = "GSE212131_series_matrix.txt.gz")
als_data <- as.data.frame(t(als@assayData[["exprs"]]))
```

Extracting the data set from the file, and transposing them to have the variables on the columns.
Checking if there is some aberrations in the data.

```{r, echo = FALSE}
anyNA(als_data)
als@experimentData@title
als@experimentData@abstract
```

We have to see the distributions for every sample to notice if there are some messy stuff.
We are looking for a good maintenance of the media, 2nd and 3rd quantile.

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
boxplot(t(als_data), main = "Boxplot",  xaxt = "n")
```

The variables (genes) distributions are quite stable so I will not further modify them.

## Integrating the data with more information

Now we have to complete the data set with some important information like: the group ctrl and treated, gender and other thing in base of our data.

```{r}
gender <- als@phenoData@data[["gender:ch1"]]
time <- c()
for (i in (1:22)){
  time <- append(time, "Short")
}
for (i in (1:20)){
  time <- append(time, "Long")
}

vec <- c()
genes_names <- c()
for ( i in (1:ncol(als_data))){
  gene <- unlist(str_split(als@featureData@data[["gene_assignment"]][i], " // "))[2]
  if (is.na(gene)){
    vec[i] <- FALSE
    genes_names[i] <- "CTRL"
  }
  else {
    vec[i] <- TRUE
    genes_names[i] <- gene
  }
}

colnames(als_data) <- genes_names
als_contrl <- als_data[, !vec]
als_data <- als_data[, vec]
IDs <- als@featureData@data[["ID"]][vec]
genes_num <- 1:length(als_data)

als_data$Gender <- gender
als_data$Time <- time
rownames(als_data) <- als@phenoData@data[["title"]]
```

# Exploratory analysis

##PCA

I've started the exploratory analysis running a PCA on the hole data, the first one is divided by the two groups; Short and Lond. While the second is split by the gender.

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
pca <- als_data[,genes_num] %>% prcomp
# summary(pca) 
screeplot(pca)

# draw PCA plot 
grpcol <- c(rep("darkgreen",22), rep("darkorange",20))
plot(pca$x[,1], pca$x[,2], xlab="PCA1",
     ylab="PCA2", main="PCA for components 1&2",
     type="p", pch=19, col = grpcol)
```

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
dim(als_data[als_data$Gender == "Female",])
pca_g <- als_data[,genes_num] %>% prcomp
coll <- c(rep("pink",13),rep("skyblue",42-13))

plot(pca$x[,1], pca$x[,2], xlab="PCA1",
     ylab="PCA2", main="PCA for components 1&2",
     type="p", pch=19, col = coll)
```

```{r include = FALSE}
comp <- as.data.frame(pca$x)
plot_ly(comp, x = ~PC1, y = ~PC2, z = ~PC3, color = grpcol)
```

## Cleaning

Is not possible to continue the analysis keeping all the features, because i will only maintain noise. So I have filtered the data using a T test to evaluate the p-value and use a cutoff for it of 0.99. 

```{r}
p_value <- c()
for (i in genes_num){
  t <- t.test(als_data[als_data$Time == "Short", i],
              als_data[als_data$Time == "Long", i])
  p_value <- append(p_value, t$p.value)
}
```

```{r}
threshold <- 0.01
imp_genes <- p_value < threshold
sub_meaning <- als_data[, imp_genes]
genes_num <- 1:length(sub_meaning)
sub_meaning <- sub_meaning %>% mutate(Gender = gender, Time = time)
```

Here there is an other feature selection method, which use the variance and select only the 5 percent of gene more variable. I've made also a function to calculate the fold change of the expression (which in my opinion is not functioning well due to the data are not in their raw form).

```{r}
var <- c()
for (i in 1:(length(als_data)-2)){
  var <- append(var, sd(als_data[,i]))
}
filter <- var > quantile(var, 0.95)
als_var <- als_data[, filter]
als_var <- als_var %>% mutate(Time = time)
```

```{r}
logFC <- c()
ff <- function(range1, range2, data,col){
  m1 <- mean(data[range1, col])
  m2 <- mean(data[range2, col])
  return(m2/m1)
}
for (i in ( 1:ncol(sub_meaning)-2)){
  logFC <- append(logFC, ff(1:22,23:42, sub_meaning, i))
}
logFC <- na.omit(logFC)
```

I've constructed a data set wit some useful information, as genes names, logFC and p-value, that I probably would use later.

```{r include = FALSE}
ensembl <- useEnsembl(biomart = "ensembl",dataset = "hsapiens_gene_ensembl")

query <- getBM(attributes = c("entrezgene_id", "gene_biotype", "external_gene_name"),
               filters = c("hgnc_symbol"),
               values = list(c(colnames(als_data)[imp_genes])),
               mart = ensembl)
dat <- data.frame(external_gene_name = colnames(als_data)[imp_genes], p_value = p_value[imp_genes], logFC = logFC)
dat <- merge(dat, query[, c(1,3)], by = "external_gene_name")
```

## Second PCA

Here there is a second PCA exploited with the reduced data.

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
pca_second <- sub_meaning[,genes_num] %>% prcomp

screeplot(pca_second)
plot(pca_second$x[,1], pca_second$x[,2], xlab="PCA1",
     ylab="PCA2", main="PCA for components 1&2",
     type="p", pch=19, col = grpcol)

```

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
pcc <- sub_meaning %>% arrange(Gender) %>%
  dplyr::select(-Gender, -Time) %>% prcomp

plot(pcc$x[,1], pcc$x[,2], xlab="PCA1",
     ylab="PCA2", main = "PCA for components 1&2",
     type="p", pch=19, col = coll)
```

```{r include=FALSE}
com <- as.data.frame(pca$x)
plot_ly(com, x = ~PC1, y = ~PC2, z = ~PC3, color = grpcol)
```

## K means clustering and Hierarchical clustering

To continue the exploratory analysis I've performed K-means and Hierarchical clustering.

```{r fig.width = 10, fig.height = 6, fig.align = "center", echo = FALSE}
k <- 2
kmeans_result <- kmeans(sub_meaning[,genes_num], k)
kmeans_result$totss
table(kmeans_result$cluster)
plot(kmeans_result, data = sub_meaning, main = "K-means Sub_meaning")+
  geom_text(aes(label =rownames(sub_meaning)), hjust = 0, vjust = 0)
```

```{r}
dist_matrix <- dist(sub_meaning[,genes_num])
hc_res <- hclust(dist_matrix, method = "complete")
k <- 2
groups <- cutree(hc_res, k =k)
table(groups)
plot(hc_res, hang = -1, labels = rownames(als_data), xlab = "Complete linkage")
rect.hclust(hc_res, k = 2, which = c(1,2), x = NULL, h = NULL, cluster = NULL, border = c("darkgreen", "darkorange"))
```

# Model selection

In this section I've evaluated some predictive models to find the most performing, the idea is to use the best one to reduce further the features and use only them to make inference. The model used hereafter are: logistic regression, Random Forrest, Ridge, Lasso, Support Vector Machines and SCUDO. To reduce noise and "instability" I used only, when possible, the carel library.

```{r}
train <- createDataPartition(sub_meaning$Time, p = 0.65, times = 1, list = F)
test <- setdiff(1:42, train)

mod <- lda(Time ~ ., data = sub_meaning, prior = c(0.5,0.5), subset = train) 
plot(mod) 

mod.values <- predict(mod, sub_meaning[train,]) 
mod.values$class 

plot(mod.values$x[,1], ylab = c("LDA Axis"), pch = 19, col = as.factor(sub_meaning$"Time"[train]))
text(mod.values$x[,1])
preds <- predict(mod, sub_meaning[test,]) 
preds$class 
table(preds$class, sub_meaning$Time[test])

roc_lda<- plot.roc(as.numeric(preds$class),
                   as.numeric(as.factor(sub_meaning[test, "Time"])))
```

```{r}
control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
metric <-  "accuracy"

fit.lda.2 <- train(Time ~ ., data = sub_meaning, method = "lda", metric = metric, trControl = control) 
fit.rf.2 <- train(Time ~ ., data = sub_meaning, method = "rf", metric = metric, trControl = control)

results <- resamples(list(LDA = fit.lda.2, RF = fit.rf.2))
ggplot(results) + labs(y = "Accuracy")
```

```{r}
app <- apply(sub_meaning[,genes_num],2,scale)
heatmap(app, col = colorRampPalette(brewer.pal(8, "Blues"))(25))
```

## Random forest

```{r}
y <- c(rep('S',22),rep('L',20))
rf <- randomForest(x = sub_meaning[,genes_num], as.factor(y), ntree = 5000) 

plot(sort(rf$importance, decreasing=TRUE))    
varImpPlot(rf) 
#extract the most 'important' genes 
probe.names <- rownames(rf$importance) 
top200 <- probe.names[order(rf$importance, decreasing=TRUE)[1:200]] 
plot(rf)
```

## Glm net

```{r}
f <-  factor(time, labels = c("Short","Long"))
fit <- glmnet(sub_meaning, time, standardize = FALSE, family = "binomial")

plot(fit, xvar = "lambda", label = TRUE) 
cfit <- cv.glmnet(as.matrix(sub_meaning[, genes_num]), time,
                  standardize = FALSE, family="binomial") 

plot(cfit)
coef_ <- coef(cfit, s = cfit$lambda.min)

fit <- glmnet(sub_meaning[train, genes_num], time[train],
              standardize = FALSE, family = "binomial") 
plot(fit) 

cfit <- cv.glmnet(as.matrix(sub_meaning[train, genes_num]),time[train],
                  standardize = FALSE, family="binomial")
plot(cfit)
```

```{r}
pred2 <- predict(fit, as.matrix(sub_meaning[test, genes_num]),
        type = "class", s = cfit$lambda.min)
accur <- mean(pred2 == time[test])
accur

pred2 <- predict(fit, as.matrix(sub_meaning[test, genes_num]),
                 type = "response", s = cfit$lambda.min)
plot(performance(prediction(pred2, time[test]), 'tpr', 'fpr')) 


auc.tmp <- performance(prediction(pred2, time[test]), "auc") 
as.numeric(auc.tmp@y.values)
```

```{r}
# GLM with train
glm.fit <- train(Time ~ ., data = sub_meaning, method = "glm", family = "binomial",
                metric = metric, trControl = control) 
results <- resamples(list(LDA = fit.lda.2, RF = fit.rf.2, GLM.binom = glm.fit))
ggplot(results) + labs(y = "Accuracy")
```

## Ridge

```{r}
fit.ridge <- train(Time ~., data = sub_meaning, method = "glmnet",
                 family = "binomial",
                 tuneGrid= expand.grid(alpha = 0, lambda = seq(0,1,by=0.05)),
                 trControl= control,
                 metric = metric)
plot(fit.ridge)
results <- resamples(list(RF = fit.rf.2, LDA = fit.lda.2, GLM.binom = glm.fit, Ridge = fit.ridge))
ggplot(results) + labs(y = "Accuracy")
```

## Lasso

```{r}
fit.lasso <- train(Time ~., data = sub_meaning, method = "glmnet",
                 family = "binomial",
                 tuneGrid= expand.grid(alpha = 1, lambda = seq(0,1,by=0.05)),
                 trControl= control,
                 metric = metric)
plot(fit.lasso) 

# comparison with other classification methods 

results <- resamples(list(RF = fit.rf.2, LDA = fit.lda.2, Lasso = fit.lasso, GLM.binom = glm.fit, Ridge = fit.ridge))
summary(results) 
ggplot(results) + labs(y = "Accuracy")
```

##SVM

```{r}
# svm
svm.pol.fit <- train(Time ~., data = sub_meaning, method = "svmPoly", trControl= control, metric = metric)

svm.lin.fit <- train(Time ~., data = sub_meaning, method = "svmLinear", trControl= control, metric = metric)

results <- resamples(list(RF = fit.rf.2, LDA = fit.lda.2, Lasso = fit.lasso, GLM.binom = glm.fit, SVM_L = svm.lin.fit, SVM_P = svm.pol.fit, Ridge = fit.ridge))
summary(results) 
ggplot(results) + labs(title = "Accuracy")
```

## With variance
```{r}
svm.pol.fit.var <- train(Time ~., data = als_var, method = "svmPoly", trControl= control, metric = metric)

svm.lin.fit.var <- train(Time ~., data = als_var, method = "svmLinear", trControl= control, metric = metric)

fit.lasso.var <- train(Time ~., data = als_var, method = "glmnet",
                 family = "binomial",
                 tuneGrid= expand.grid(alpha = 1, lambda = seq(0,1,by=0.05)),
                 trControl= control,
                 metric = metric)
fit.lda.2.var <- train(Time ~ ., data = als_var, method = "lda", metric = metric, trControl = control) 
fit.rf.2.var <- train(Time ~ ., data = als_var, method = "rf", metric = metric, trControl = control)

results <- resamples(list(RF = fit.rf.2.var, LDA = fit.lda.2.var, Lasso = fit.lasso.var, SVM_L = svm.lin.fit.var, SVM_P = svm.pol.fit.var, Logistic.reg = glm.fit))

summary(results)
ggplot(results) + labs(y = "Accuracy with variance")
```

## Scudo

For the SCUDO model I tried the data after the feature selection with the variance method, but turn out to be worse. This reduction in accuracy was clear also for the others models (see chunk 30).

```{r}
scudo_train <- t(als_var[train, 1:ncol(als_var)-1])
scudo_test <- t(als_var[test, 1:ncol(als_var)-1])

trainRes <- scudoTrain(scudo_train, groups = f[train],  nTop= 12, nBottom= 12, alpha = 0.05) 
trainRes 

upSignatures(trainRes)[1:5,1:5] 
consensusUpSignatures(trainRes)[1:5, ] 

trainNet <- scudoNetwork(trainRes, N = 0.2) 
scudoPlot(trainNet, vertex.label = NA) 

testRes <- scudoTest(trainRes, scudo_test, f[test], nTop= 12, nBottom= 12) 
testNet <- scudoNetwork(testRes, N = 0.2) 
scudoPlot(testNet, vertex.label= NA) 

testClust <- igraph::cluster_spinglass(testNet, spins = 2) 
plot(testClust, testNet, vertex.label= NA) 

classRes <- scudoClassify(scudo_train, scudo_test, N = 0.25, nTop = 12, nBottom = 12, trainGroups = f[train], alpha = 0.5)
caret::confusionMatrix(classRes$predicted, f[test])
mean(classRes$predicted == f[test])
```

```{r}
scudo_train <- t(sub_meaning[train, genes_num])
scudo_test <- t(sub_meaning[test, genes_num])

trainRes <- scudoTrain(scudo_train, groups = f[train],  nTop= 12, nBottom= 12, alpha = 0.05) 
trainRes 

upSignatures(trainRes)[1:5,1:5] 
consensusUpSignatures(trainRes)[1:5, ] 

trainNet <- scudoNetwork(trainRes, N = 0.25) 
scudoPlot(trainNet, vertex.label = NA) 

testRes <- scudoTest(trainRes, scudo_test, f[test], nTop= 12, nBottom= 12) 
testNet <- scudoNetwork(testRes, N = 0.25) 
scudoPlot(testNet, vertex.label= NA) 

testClust <- igraph::cluster_spinglass(testNet, spins = 2) 
plot(testClust, testNet, vertex.label= NA) 

classRes <- scudoClassify(scudo_train, scudo_test, N = 0.25, nTop = 12, nBottom = 12, trainGroups = f[train], alpha = 0.5)
caret::confusionMatrix(classRes$predicted, f[test])
mean(classRes$predicted == f[test])
pp <- 
write.csv(c(consensusUpSignatures(trainRes), consensusDownSignatures(trainRes)), file = "scudo_probes.txt", quote=FALSE, row.names= FALSE)

```

After computed the accuracy with SCUDO, I've used the SMV with polynomial kernel to select the features. I've also created a text file to store the gene names, ordered by importance, resulting from the selection.

```{r}
costs <- c(0.01, 0.1, 1, 3, 10)
degres <- c(1,2,3)
gammas <- c(0.001, 0.01, 0.1, 1)

data <-  sub_meaning %>% dplyr::select(-Gender)
data$Time <- as.factor(data$Time)

tune.pol <- tune(e1071::svm, Time ~ ., data = data, kernel = "polynomial",
               ranges = list(cost = costs, 
                             gamma = gammas, degree = degres),
               tunecontrol = tune.control(cross = 5))
svm_p <- e1071::svm(Time ~. , data = data,
           kernel = "polynomial", cost = tune.pol$best.parameters$cost,
           degree = tune.pol$best.parameters$degree, gamma = tune.pol$best.parameters$gamma)

w <- t(svm_p$coefs) %*% svm_p$SV      
w <- apply(w, 2, function(v){sqrt(sum(v^2))})  
w <- as.data.frame(w) %>% dplyr::arrange(desc(w))

nam <- rownames(w)[1:200]

write.csv(nam, file = "probes.txt", quote=FALSE, row.names= FALSE)

```

# Network base analysis

From now on the gene used are the ones selected by the SVM, so all the methods will exclusively utilize them.

## Gprofiler

```{r}
gostres <- gost(nam,
                organism = "hsapiens", ordered_query = FALSE, multi_query = FALSE,
                significant = TRUE, exclude_iea = FALSE, measure_underrepresentation = FALSE,
                evcodes = FALSE, user_threshold = 0.05, correction_method = "g_SCS",
                domain_scope = "annotated", custom_bg = NULL, numeric_ns = "",
                sources = NULL, as_short_link = FALSE)

names(gostres)
head(gostres$result)

# visualize results using a Manhattan plot
gostplot(gostres, capped = TRUE, interactive = TRUE)
# when ready, create publication quality (static) plot + table of interesting terms/pathways
p <- gostplot(gostres, capped = TRUE, interactive = FALSE)

publish_gostplot(p, highlight_terms = c("GO:0048013", "REAC:R-HSA-3928663"),
                 width = NA, height = NA, filename = NULL )

```

Over Representation Analysis can be performed with tools as Gprofiler and David. Out if these two
only the second had the power to interpret my data. Give as input all the 200 features retrived from
the model, the output of Gprofiler can be seen in figure 10 in attachment. All the point lie in the
region of transcription factors, this mean that the majority of the gene are related with the switching
of the transcription pattern of cells. Although all the point shown can’t reach the p-value threshold
(setted by the tools) is remarkable the redundancy of provenience from transcription factor database,
and make also sense that a possible division between the groups is formed by transcription factors. Is
also to mention that a small part of the features selected were not been found from the tools, some of
them are Open Reading Frame (ORF) protein or related factors.


# Pathfinder

```{r}
library(pathfindR)
dat <- dat[dat[,1]%in%nam, ]
dat <- na.omit(dat)
#write.csv(dat[,1], file = "Probesss.txt", quote=FALSE, row.names= FALSE)


pathfindR_results <- run_pathfindR(dat[,1:2], iterations = 1) 
pathfindR_cluster <- cluster_enriched_terms(pathfindR_results)

RA_demo2 <- run_pathfindR(dat[,1:2],
                          gene_sets = "Reactome",
                          pin_name_path = "KEGG")
pathfindR_cluster <- cluster_enriched_terms(RA_demo2)
term_gene_graph(pathfindR_results)
term_gene_graph(RA_demo2)
```

At last was performed network analysis to search for connections between features and highlight important pathways to differentiate the two groups. This procedure was firstly done with the pathfindR
library, which results are visible in figure 5 and sequentially with STRING. The mosts enriched pathways are (as shown in figure 5) the complement cascade, G alpha signaling events and the RHOA
family. The complement cascade is related to an inflammatory environment and clear microbes and
damaged cells. G alpha signaling evens take place during the transduction of signaling through the
GTP-GDP and cyclic GMP switch. The RHOA family instead is composed by GTPases proteins,
which are responsable mainly for the transduction of signaling and more in specific to the remodelling
of the cythoskeleton, actin stress fibers formation and actomyosin contraction.

## STRING

```{r}
links <- read.delim("string_interactions_short.tsv")
vec <- links$X.node1%in%nam
links <- links[vec,]
vec <- links$node2%in%nam
links <- links[vec,]

net <- graph_from_data_frame(d = links, vertices = nam, directed = FALSE)
net_clean <- simplify(net)

# Plot graph
plot(net_clean)

c <- components(net_clean, mode =  c("weak","strong"))
## find max and position
max(c$csize)
net_work <- which.max(c$csize)
net.c <-  induced_subgraph(net_clean,V(net_clean)[which(c$membership == net_work)])

plot(net.c)

ceb <- cluster_edge_betweenness(net.c) 
ceb
plot(ceb, net.c, vertex.size = 10)
```

```{r}
# Plots
plot(pca$x[,1], pca$x[,2], xlab="PCA1",
     ylab="PCA2", main="(a) PCA for components 1&2",
     type="p", pch=19, col = grpcol)
legend("bottomright", legend = c("Short", "Long"), col = c("darkgreen","darkorange"), lwd = 4)
plot(pca_second$x[,1], pca_second$x[,2], xlab="PCA1",
     ylab="PCA2", main="(b) PCA for components 1&2",
     type="p", pch=19, col = grpcol)
legend("topright", legend = c("Short", "Long"), col = c("darkgreen","darkorange"), lwd = 4)

dev.off()
```

As regard the STRING tool, all the 200 genes was gave as input at the tools, and as before some
genes were not recognised. STRING is a database of protein protein interaction, so the output is a
connected network; the links between proteins can be known interactions (data coming from literature)
and predicted interactions. Out of the all genes given in input, was kept only those which created the
biggest sub cluster, very few proteins connections were cutted out. In the figure 6 is represent the
resulting sub cluster, in which are highlight with different colors smaller groups of protein more deep
link.
